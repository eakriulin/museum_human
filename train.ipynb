{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUN1Yh5ekfpa"
      },
      "source": [
        "# Training on the Crowd Human Dataset\n",
        "\n",
        "The model is first trained on the well-known [Crowd Human](https://www.crowdhuman.org/) dataset. This dataset helps the model learn the basic features needed to detect human bodies and heads in images effectively.\n",
        "\n",
        "Note: This training process is optimized to run on Google Colab with GPU support, which significantly speeds up the computations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6BN6hPQxcAwl"
      },
      "outputs": [],
      "source": [
        "# Install the library with YOLO models\n",
        "%pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG7UkwnTcL3Y"
      },
      "outputs": [],
      "source": [
        "from ultralytics import settings, YOLO\n",
        "settings.update({\"wandb\": False})\n",
        "\n",
        "# Load a COCO-pretrained YOLO11n model\n",
        "model = YOLO(\"yolo11n.pt\")\n",
        "\n",
        "# Train the model on the Crown Human dataset for 100 epochs\n",
        "model.train(\n",
        "    data=\"/content/drive/MyDrive/crowd_human/data.yaml\", # Path to the dataset configuration file in YAML format\n",
        "    project=\"/content/drive/MyDrive/crowd_human/runs\",   # Directory to save training results and logs\n",
        "    epochs=100,                                          # Number of training epochs\n",
        "    batch=16,                                            # Batch size for training\n",
        "    imgsz=640,                                           # Input image size (width and height)\n",
        "    device=0,                                            # GPU device ID (use 0 for the first GPU, or 'cpu' for CPU training)\n",
        "    save=True,                                           # Whether to save the trained model and checkpoints\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAq_oNQSlhc4"
      },
      "source": [
        "# Fine-Tuning on Custom Dataset\n",
        "\n",
        "The next step is to fine-tune the model using a custom-labeled dataset obtained from original museum videos. This process is necessary to address several challenges:\n",
        "\n",
        "1. Background: The museum environment contains numerous statues and exhibits that the pre-trained model frequently misclassifies as human beings.\n",
        "2. Site Conditions: The museum videos have distinctive camera angles and lighting conditions that are not adequately represented in the Crowd Human dataset, necessitating adaptation.\n",
        "3. Crowd Densities: The model needs to see the museum-specific crowd densities to improve its prediction confidence and accuracy.\n",
        "\n",
        "The custom dataset comprises 230 images, split into 220 images for training and 10 images for validation. Given the small size of the dataset, the validation set has been handcrafted to include both trivial and non-trivial scenarios:\n",
        "\n",
        "- Trivial Scenarios: All human beings in the room are fully visible.\n",
        "- Non-Trivial Scenarios Some human beings are partially obscured (either by other visitors or by exhibition items) requiring the model to handle occlusions effectively.\n",
        "\n",
        "The fine-tuning process ensures the model adapts to the nuances of the museum environment. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiZbULEql43l"
      },
      "outputs": [],
      "source": [
        "from ultralytics import settings, YOLO\n",
        "settings.update({\"wandb\": False})\n",
        "\n",
        "# Load the best weights from the Crown Human training session\n",
        "model = YOLO(\"/content/drive/MyDrive/crowd_human/runs/train/weights/best.pt\")\n",
        "\n",
        "model.train(\n",
        "    data=\"/content/drive/MyDrive/museum_human/data.yaml\", # Path to the dataset configuration file in YAML format\n",
        "    project=\"/content/drive/MyDrive/museum_human/runs\",   # Directory to save training results and logs\n",
        "    epochs=100,                                           # Number of training epochs\n",
        "    batch=16,                                             # Batch size for training\n",
        "    imgsz=960,                                            # Input image size (width and height)\n",
        "    device=0,                                             # GPU device ID (use 0 for the first GPU, or 'cpu' for CPU training)\n",
        "    save=True,                                            # Whether to save the trained model and checkpoints\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4wM0M_X2k8y"
      },
      "source": [
        "# Results\n",
        "\n",
        "The model performed well on key object detection metrics:\n",
        "\n",
        "- mAP50: 0.986  \n",
        "  Indicates excellent detection accuracy with minimal localization errors.  \n",
        "\n",
        "- mAP50-95: 0.757  \n",
        "  Shows good detection accuracy even under stricter IoU thresholds.  \n",
        "\n",
        "- Box Precision: 0.95  \n",
        "  Reflects strong agreement between predicted boxes and ground truth boxes."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
